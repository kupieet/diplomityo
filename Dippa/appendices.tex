\chapter{Search strings}
\label{app:Strings}

The first search string was:

TITLE-ABS-KEY(software AND (agile OR lean OR "crystal method" OR "crystal
clear" OR dsdm OR "dynamic systems development method" OR fdd OR "feature
driven development" OR "agile unified process" OR "agile modeling" OR scrumban
OR kanban OR scrum OR "extreme programming" OR xp) AND (measur* OR metric OR
diagnostic OR monitor*)) AND (LIMIT-TO(SUBJAREA, "COMP")) AND
(LIMIT-TO(LANGUAGE, "English"))\\

It found 512 hits 19 September 2013.\\\\

%Then we noticed that some previously found key papers were missing from the
%hits because they were under sub area ``Engineering'', thus 
The second search string was:\\

TITLE-ABS-KEY(software AND (agile OR lean OR "crystal method" OR "crystal
clear" OR dsdm OR "dynamic systems development method" OR fdd OR "feature
driven development" OR "agile unified process" OR "agile modeling" OR scrumban
OR kanban OR scrum OR "extreme programming" OR xp) AND (measur* OR metric OR
diagnosticOR monitor*)) AND (LIMIT-TO(LANGUAGE, "English")) AND
(LIMIT-TO(SUBJAREA, "ENGI")) AND (EXCLUDE (SUBJAREA, "COMP") OR
EXCLUDE(SUBJAREA, "PHYS") OR EXCLUDE(SUBJAREA,"MATE") OR EXCLUDE (SUBJAREA,
"BUSI") OR EXCLUDE(SUBJAREA, "MATH") OR EXCLUDE(SUBJAREA, "ENVI") OR
EXCLUDE (SUBJAREA, "EART") OR EXCLUDE(SUBJAREA, "DECI") OREXCLUDE (SUBJAREA,
"ENER"))\\

It found 220 hits 7 November 2013.\\\\

The third search string was:\\

TITLE-ABS-KEY(software AND (agile OR lean OR "crystal method" OR "crystal
clear" OR dsdm OR "dynamic systems development method" OR fdd OR "feature
driven development" OR "agile unified process" OR "agile modeling" OR scrumban
OR kanban OR scrum OR "extreme programming" OR xp) AND (measur* OR metric OR
diagnosticOR monitor*)) AND (LIMIT-TO(LANGUAGE, "English")) AND
(LIMIT-TO(SUBJAREA, "BUSI")) AND (EXCLUDE (SUBJAREA, "ENGI") OR
EXCLUDE(SUBJAREA, "COMP"))\\

It found 42 hits 10 December 2013.

\chapter{Inclusion and exclusion criteria}
\label{app:Criteria}

Inclusion criteria
\begin{itemize}
  \item Papers that present the use and experiences of metrics in an agile
  industry setting.
\end{itemize}

Exclusion criteria
\begin{itemize}
  \item Papers that don't contain empirical data from industry cases.
  \item Papers that are not in English.
  \item Papers that don't have agile context. There is evidence of
  clearly non-agile practices or there is no agile method named. For example,
  paper mentions agile but case company has only three releases per year.
  \item Paper is only about one agile practice, which is not related to
  measuring.
  \item Papers that don't seem to have any data about metric usage. Similarly,
  if there are only a few descriptions of metrics but no other info regarding
  reasons or usage.
  \item Papers that have serious issues with grammar or vocabulary and
  therefore it takes considerable effort to understand sentences.
  %\item Papers that refer to another paper where the actual case is discussed.
  %\item Papers that are in academic or semi-academic setting - customer or
  %part of workers are from industry. The reason for this is that it doesn't
  %fully represent industry setting as software development methods are likely
  %enforced by academia. \juha{tämä sisältyy tai vain tarkentaa ensimmäistä}
  \item Papers where the setting is not clear or results cannot be separated by setting, for example
  surveys where there is data both from academia and industry. %Similar
%  exclusion if results cannot be separated by software development method. 
  %\item Papers where the setting is not clear. For example only mention of
  %context is ``100 junior developers''.\juha{yhdistin edelliseen}

  %%\item Papers that are full conference proceedings. Individual papers should be already listed separately.
  \item Papers where the measurements are only used for the research. For
  example author measures which agile practices correlate with success.
  %%\item Papers that don't even show measurement usage in a pilot setting. For
  %%example method or metric is used against static industrial data set. \juha{tämä sisältyy tai vain tarkentaa ensimmäistä}
\end{itemize}

\chapter{Quality assesment questions}
\label{app:quality}

\begin{enumerate}
  \item Is this a research paper?
  \item Is there are a clear statement of the aims of the research?
  \item Is there an adequate description of the context in which the research
  was carried out?
  \item Was the research design appropriate to address the aims of the
  research?
  \item Was the recruitment strategy appropriate to the aims of the research?
  \item Was there a control group with which to compare treatments?
  \item Was the data collected in a way that addressed the research issue?
  \item Was the data analysis sufficiently rigorous?
  \item Has the relationship between researcher and participants been
  considered adequately?
  \item Is there a clear statement of findings?
  \item Is the study of value for research or practice?
\end{enumerate}

\chapter{Metric distribution by primary studies}
\label{app:Metrics}
%\centering
\caption{Metrics by primary studies}
\label{tab:Metrics} 
\begin{longtable}{lp{10cm}} \hline
ID & Metrics\\
\hline 
[S1] & Business value delivered, customer satisfaction, defect count
after testing, number of test cases, running tested features\\ \relax
[S2] & Velocity\\ \relax
[S3] & Team available hours, team
effective hours, critical defects sent by customer, open defects, test
failure rate, test success rate, remaining task effort, team effectiveness\\
\relax
[S4] & Technical debt in categories, build status,
technical debt in effort\\\relax
[S5] & Burndown, check-ins per day, number of automated test steps, faults
per iteration\\\relax
[S6] & Velocity, story estimates\\\relax
[S7] & Burndown, story points, \# of open defects, defects found
in system test, defects deferred, net promoter score\\\relax
[S8] & Story points, task effort, velocity, operation's
velocity\\\relax
[S9] & Effort estimate, actual effort\\\relax
[S10] & \# of defects/velocity\\\relax
[S11] & Revenue per customer\\\relax
[S12] & Task's expected start and end date, effort estimate,
completed web pages, task done\\\relax
[S13] & Fix time of failed build, story flow percentage,
percentage of stories prepared for sprint, velocity of elaborating features,
velocity of implementing features\\\relax
[S14] & Broken build, test coverage, test growth ratio, violations
of static code checks, \# of unit tests\\ \relax
[S15] & Effort estimate, effort estimate, effort estimate, effort
estimate\\\relax
[S16] & Sprint burndown, release burndown, cost
performance index, schedule performance index, planned velocity\\\relax
[S17] & Common tempo time, number of bounce backs, cycle
time, work in progress, customer satisfaction(Kano analysis), effort
estimate kits, inventory per phase\\\relax
[S18] & Lead time, processing time, queue time\\\relax
[S19] & Change requests per requirement, fault slips,
implemented vs wasted requirements, maintenance effort, lead time\\\relax
[S20] & Rate of requirements per phase, variance in handovers,
requirement's cost types\\\relax
[S21] & number of maintenance requests, number of work items
per phase, lead time\\\relax
[S22] & \# of faults, fault-slip-through, \# of
requests from customers, \# of requirements per phase, lead time\\\relax
[S23] & Work in progress, average velocity, cycle time, pseudo
velocity\\\relax
[S24] & Lead time, work in progress, \# of days in maintenance,
\# of days to overdue, reported hours on CSR\\\relax
[S25] & Number of features developed in release, queue,
throughput\\\relax
[S26] & Defect trend indicator, \# of defects in backlog,
predicted \# of defects\\\relax
[S27] & Burndown, check-ins per day, number of automated test steps\\\relax
[S28] & Burndown, \# of new defects, number of written and passed tests,
task estimated vs actual time, time reported for overhead activities,
check-ins per day\\\relax
[S29] & Story estimate, story complete percentage\\\relax
[S30] & Progress as working code\\\relax
[S31] & Costs, schedule\\\relax
\hline
\end{longtable}




