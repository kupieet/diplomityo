% This is "sig-alternate.tex" V2.0 May 2012
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}
\usepackage{nameref}
\usepackage[usenames]{color}
\usepackage{cleveref}
\usepackage{booktabs}
\usepackage{comment} 

\newcommand{\basicalert}[2]{\fbox{\bfseries\sffamily\scriptsize\color{blue} #1}{\sf\small$\blacktriangleright$\textit{\color{red} #2}$\blacktriangleleft$} }
\newcommand{\mika}[1]{\basicalert{From Mika}{#1}}
\newcommand{\eetu}[1]{\basicalert{From Eetu}{#1}}
\newcommand{\juha}[1]{\basicalert{From Juha}{#1}}
%\newcommand{\mika}[1]{\ignorespaces}
%\newcommand{\eetu}[1]{\ignorespaces}
%\newcommand{\juha}[1]{\ignorespaces}

\begin{document}

%
% --- Author Metadata here ---
\conferenceinfo{WETSoM}{'14 Hyderabad, India}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---


\title{Why are industrial agile teams using metrics and how do they use them?
// Agile metrics in industry: systematic literature review }
%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as
%\textit{Author's Guide to Preparing ACM SIG Proceedings Using
%\LaTeX$2_\epsilon$\ and BibTeX} at
%\texttt{www.acm.org/eaddress.htm}}}

%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Eetu Kupiainen\\
       \affaddr{Department of Computer Science and Engineering}\\
       \affaddr{Aalto University}\\
       \affaddr{FI- 00076 AALTO, FINLAND}\\
       \email{eetu.kupiainen@aalto.fi}
% 2nd. author
\alignauthor
Mika Mäntylä\\
       \affaddr{Department of Computer Science and Engineering}\\
       \affaddr{Aalto University}\\
       \affaddr{FI- 00076 AALTO, FINLAND}\\
       \email{mika.mantyla@aalto.fi}
% 3rd. author
\alignauthor
Juha Itkonen\\
       \affaddr{Department of Computer Science and Engineering}\\
       \affaddr{Aalto University}\\
       \affaddr{FI- 00076 AALTO, FINLAND}\\
       \email{juha.itkonen@aalto.fi}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
%\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Agile development methods are increasing in popularity, yet there are limited
studies on the reasons and use of metrics in industrial agile development.
This paper present preliminary results from a systematic literature review. Metrics and
their use is focused to the following areas:
\nameref{sec:IterationPlanning}, \nameref{sec:IterationTracking},
\nameref{sec:Motivate}, \nameref{sec:ProblemIdentification},
\nameref{sec:PreQuality}, \nameref{sec:PostQuality} and
\nameref{sec:ChangesInProcesses}. The findings are mapped against agile
principles and it seems that the use of metrics supports the principles. 
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[agile metrics]

\terms{Measurement}

\keywords{agile software development, metrics, measurement, systematic
literature review}

\section{Introduction}

% Software engineering is at a crossroads as there are new leaner and more
% agile software development methods appearing next to the traditional
% software development methods.
\mika{Kappaleen pointti: No literature reviews of actual metric use}
Software metrics have been studied for decades and several literature reviews
have been published.
Yet, the literature reviews have been written from an academic viewpoint that
typically focuses on the effectiveness of a single metric. For example, Catal
et al. review fault prediction metrics \cite{catal2009systematic}, Purao et
al. review metrics for object oriented systems \cite{purao2003product} and
Kitchenham performs a mapping of most cited software metrics
papers \cite{kitchenham_whats_2010}. To our knowledge there are no systematic
literature reviews on the actual use of software metrics in the industry.

\mika{Kappaleen pointti: Agile on tärkeää eikä metriikkoja tutkittu}

\juha{Yritin konkretisoida trad vs. agile kontrastia}
Agile software development is becoming increasing popular in the software
industry. The agile approach seems to be contradicting with the traditional
metrics approaches. For example, the agile emphasizes working software over measuring progress in terms of intermediate products or documentation, and embracing the change invalidates the traditional approach of tracking progress against pre-made plan.
However, at the same time agile software development
highlights some measures that should be used, e.g., burndown graphs and 100\%
automated unit testing coverage. However, measurement research in the context of agile
methods remains scarce.

The goal of this paper is to review the literature of actual use of software
metrics in the context of agile software development. This study will lay out
the current state of metrics usage in industrial agile software development
based on literature.
Moreover, the study uncovers the reasons for metric usage as well as
highlights actions that the use of metrics can trigger. Due to our research
goal, we focus this paper on case studies and actual empirical findings
excluding theoretical discussion and models lacking empirical validation.
% The performed SR has more research questions but for this paper only
In this paper we, cover the following research questions:

\begin{enumerate}
  \item Why are metrics used?
  \item What actions do the use of metrics trigger?
  \item Which metrics are used?
\end{enumerate}

This paper is structured as follows. \Cref{sec:Method} describes how
the SR was conducted. \Cref{sec:Results} reports the results from the study.
\Cref{sec:Discussion} discusses about the findings and how they map to agile
principles. \Cref{sec:Conclusions} concludes the paper and suggests next
steps.

%\section{Background}

%\subsection{Agile software development}
%\eetu{tässä voisi olla historianäkökulma, voipi mennä pitkäks eikä niin
%mielenkiintoinen ehkä tässä paperissa} 

%Agile development methods have emerged to the software world ruled by
%traditional heavyweight methods. In agile methods the focus is in lightweight
%working practices, constant deliveries and customer collaboration over long
%planning periods, heavy documentation and inflexible development phases.

%Agile manifesto created by agile enthusiasts \cite{beck2001agile} lists agile
%principles that give an idea what is agile development about. Popular agile
%development methods include Scrum \cite{schwaber2002agile}, Extreme
%Programming \cite{beck2004extreme} and Kanban \cite{anderson2010kanban}.



%\subsection{Evidence based software engineering}

%\subsection{Measurement}
%According to Fenton et al.\cite{fenton1998software} ``Measurement is the
%process by which numbers of symbols are assigned to attributes of entities in
%the real world in such way as to describe them according to clearly defined
%rules.''

%\subsection{Previous metric research}

%There are a few mapping studies on software metrics(tähän vois lisätä ne
% kitch whats 2010:ssä olevat muut mut en tiiä mitä lisäarvoa ne tois).
%\cite{kitchenham_whats_2010} says there is a large body of research related
% to software metrics. However, she highlights that all evidence should be
%critically appraised so that further studies can be based on good quality
%evidence. She also reminds researchers to understand the context where
% metrics are taken from - failure to understand context will probably not provide
%answers to industry-related questions. 

%--EBSE
%--Mittaamisen SR:t
%--Agile mittaamisen muut tutkimukset vai enemmänkin tutkimuksessa käytettyjen
%termien ja käsitteiden selittäminen


% \subsection{Aims and research questions} The aim of this paper is to provide
% preliminary results from a systematic review (SR) on agile metrics.
%Moreover, we are interested on the industrial use of metrics in agile
% context.



\section{Review method}
\label{sec:Method}
Systematic Review (SR) was chosen as research method because we are trying to understand a problem
instead of trying to find a solution to it. Also, there was already
existing literature that could be synthesized.

\subsection{Protocol development}
Kitchenham's guide for SRs \cite{kitchenham2004procedures} was used as a basis
for developing the review protocol. Additionally, a SR on agile development
\cite{dyba_empirical_2008} and a SR on SR \cite{kitchenham2013systematic} were
used to further understand the challenges and opportunities of SRs. The
protocol was also iterated in weekly meetings with the authors, as well as in a pilot study.

%otherguidelines \cite{webster2002analyzing}, a lessons learned from SRs
% \cite{brereton2007lessons},
\subsection{Search and selection process}

The strategy for finding primary studies was following:

\begin{itemize}
  \item Stage 1: Automated search
  \item Stage 2: Selection based on title and abstract
  \item Stage 3: Selection based on full text. Conduct data
  extraction and quality assessment.
\end{itemize}

\Cref{SelectionFunnel} shows the selection funnel in terms of the number
of papers after each stage.

%\includegraphics{SelectionFunnel.jpg}

\begin{table}
\centering
\caption{Paper selection funnel}
\begin{tabular}{|l|c|r} \hline
\label{SelectionFunnel}
\textbf{Phase} & \textbf{Amount of papers} \\ \hline
Phase 1 & 774 \\ \hline 
Phase 2 & 163 \\ \hline
Phase 3 & 29\\
\hline
\end{tabular}
\end{table}

% \subsubsection{Search strings}
Scopus database \footnote{http://www.scopus.com} was used to find the primary
documents with automated search. Keywords include popular agile development
methods and synonyms for the word metric. The search was improved
incrementally in three phases because we noticed some key papers and XP conferences were not
found initially. The search strings, hits and dates can be found from
\cref{app:Strings}.

\juha{Laittaisin myös inclusion ja exclusion kriteerit appendixiin ja jättäisin vain tämänkaltaisen lyhyen kuvauksen tänne}
The selection of the primary documents was based on an inclusion criteria:
\emph{papers that present empirical findings on the industrial use and
experiences of metrics in agile context.} The papers were excluded based on
multiple criteria, mainly due to not conforming our requirements regarding
empirical findings, agile and industrial context, and the quality of the
results. Full criteria are listed in \cref{app:Criteria}.

\juha{Inclusion criteria ja exclusion criteria siirretty -> appendix}
%\subsubsection{Inclusion criteria} \juha{->APPENDIX}
%
%\begin{itemize}
%  \item Papers that present the use and experiences of metrics in an agile
%  industry setting.
%\end{itemize}
%
%\subsubsection{Exclusion criteria} \juha{->APPENDIX}
%
%\begin{itemize}
%  \item Papers that don't contain empirical data from industry cases.
%  \item Papers that are not in English.
%  \item Papers that don't have agile context. There is evidence of
%  clearly non-agile practices or there is no agile method named. For example,
%  paper mentions agile but case company has only three releases per year.
%  \item Paper is only about one agile practice, which is not related to
%  measuring.
%  \item Papers that don't seem to have any data about metric usage. Similarly,
%  if there are only a few descriptions of metrics but no other info regarding
%  reasons or usage.
%  \item Papers that have serious issues with grammar or vocabulary and
%  therefore it takes considerable effort to understand sentences.
%  \item Papers that refer to another paper where the actual case is discussed.
%  \item Papers that are in academic or semi-academic setting - customer or
%  part of workers are from industry. The reason for this is that it doesn't
%  fully represent industry setting as software development methods are likely
%  enforced by academia.
%  \item Papers where results cannot be separated by setting, for example
%  surveys where there is data both from academia and industry. Similar
%  exclusion if results cannot be separated by software development method. 
%  \item Papers where the setting is not clear. For example only mention of
%  context is ``100 junior developers''.
%  \item Papers that are full conference proceedings. Individual papers should
%  be already listed separately.
%  \item Papers where the measurements are only used for the research. For
%  example author measures which agile practices correlate with success.
%  \item Papers that don't even show measurement usage in a pilot setting. For
%  example method or metric is used against static industrial data set.
%  %\item Papers that are about the same case, from the same author and same
%  %research focus, basically the paper format has just changed slightly.
%\end{itemize}


%\subsubsection{Stage 1 - Automatic search}

In stage 1, Scopus was used as the only search engine as it contained the most
relevant databases IEEE and ACM. Also, it was able to find Agile and XP conference
papers. Only XP Conference 2013 was searched manually because it couldn't be
found through Scopus.

%\subsubsection{Pilot}
%\label{pilot}
%We conducted a pilot study in order to refine the aim of the research and get
%familiar with the research method. Moreover, it was possible to modify the
%method and tools.

%15 papers were selected for the pilot; 5 by relevance, 5 by number of
%citations, and 5 by random selection.
% \begin{itemize} \item 5 by top relevance \item 5 by top citations \item 5 by
% random \end{itemize}
%\juha{tämä mahdollista poistaa (ainakin omana alilukuna) jos tila ei
% riitä}The pilot resulted in changing citation manager tool from Zotero to Jabref.
%Also, selection by title and selection by abstract steps were joined
% together.
%The quality assessment checklist was decided based on the pilot results.

%\subsubsection{Stage 2 - Selection by title and abstract}

In stage 2, papers were included and excluded by the first author based on
their title and abstract. As the quality of abstracts can be poor in computer
science \cite{kitchenham2004procedures}, full texts were also skimmed through
in case of unclear abstracts.
% - especially introduction, case description and conclusions were checked briefly. 
Unclear cases were discussed among researchers in weekly meetings and an exclusion rule was documented if necessary.

The validity of the selection process was analysed by performing the selection for a sample of 26 papers also by the second author. The level of agreement was substantial with Kappa 0.67 \cite{landis_measurement_1977}.

%\subsubsection{Stage 3 - Selection by full text}

Stage 3 included multiple activities in one work flow. Selection by full text
was done, data was coded and quality assessment was done. Once again, if there
were unclear papers, they were discussed in meetings. Also, selection of 7
papers was conducted by the second author with an almost perfect agreement,
Kappa 1.0 \cite{landis_measurement_1977}.

\subsection{Data extraction}

Integrated coding was selected for data extraction strategy \cite{6092576}. It
provided focus to research questions but flexibility regarding findings.
Deductive coding would have been too restraining and inductive coding might
have caused too much bias. Integrated coding made it possible to create a
sample list of code categories: Why is measurement used?, How is measurement
used? and Metrics.

The coding started with the first author reading the full text and marking
interesting quotes with a temporary code. After, reading the full text first
author checked each quote and coded again with an appropriate code based on
the built understanding. In weekly meetings, we slowly built a rule set
for collecting metrics:

\begin{itemize}
  \item Collect metric only if team or company uses it.
  \item Don't collect metrics that are only used for the comparison and
  selection of development methods. 
  \item Don't collect metrics that are primarly used to compare teams.
  \item Collect metric only if something is said about why it is used or what
  actions it causes. 
\end{itemize}

Atlas.ti Visual QDA(Qualitative Data Analysis), version 7.1.x was used to
collect and synthesize the qualitative data.

To evaluate the repeatability of finding the same metrics, another researcher
coded metrics from three papers. Capture-recapture method
\cite{seber2002estimation} was then used which showed that 90\% of metrics
were found.

\subsection{Quality assessment}
Quality assessment form adopted from \cite{dyba_empirical_2008} was used to
evaluate the quality of each primary document. 
\juha{relevancy factoria ei käytetä, eikä raportoida tämän paperin tuloksissa, joten poistaisin sen selityksen, kommentoitu pois nyt}
%Additionally, a relevancy
%factor was added to the same assessment to describe how useful the paper
%was for this study. The scale for the relevancy factor is:
%
%\begin{itemize}
%  \item 0 = doesn't contain any information regarding metrics and should be
%  already excluded
%  \item 1 = only descriptions of metrics with no additional info
%  \item 2 = some useful information related to metrics
%  \item 3 = a good amount of relevant information regarding metrics and metric
%  usage
%\end{itemize}

\subsection{Data synthesis}
Data synthesis followed the steps recommended by Cruzes et al. \cite{6092576}.
Process started by going through all quotes within one code and giving each quote a
more descriptive code describing the quote in high level. Then the descriptive
codes were organized in groups based on their similarity. These groups were
then given a high level code which are seen as categories in
\cref{WhyHowCategories}.

\section{Results} % - Why and how are metrics used
\label{sec:Results}

This chapter presents the preliminary results from the systematic literature 
review. \Cref{PublicationDistribution} shows the distribution of primary
documents by publication channels. \Cref{OverviewOfPdocs} lists the
primary documents and context info.

\begin{table}
\centering
\caption{Publication distribution of primary documents}
\label{PublicationDistribution}
\begin{tabular}{llll}
\hline Publication channel & Type & \# & \%\\
\hline Agile Conference & Conference & 8 & 38\\
HICCS & Conference & 3 & 14\\
ICSE & Workshop & 2 & 10\\
XP Conference & Conference & 2 & 10\\
Agile Development Conference & Conference & 1 & 5\\
APSEC & Conference & 1 & 5\\
ASWEC & Conference & 1 & 5\\
%ECIS & Conference & 1 & 5\\
%ECSA & Conference & 1 & 5\\ 
Elektronika ir Elektrotechnika & Journal & 1 & 5\\
Empirical Software Engineering & Journal & 1 & 5\\
EUROMICRO & Conference & 1 & 5\\
ICSE & Conference & 1 & 5\\
ICSP & Conference & 1 & 5\\
%ICSSP & Conference & 1 & 5\\
IST & Journal & 1 & 5\\
IJPQM & Journal & 1 & 5\\
JSS & Journal & 1 & 5\\
PROFES & Conference & 1 & 5\\
Software - Prac. and Exp. & Journal & 1 & 5\\
WETSoM & Workshop & 1 & 5\\
\hline

\end{tabular}
\end{table}

% Table generated by Excel2LaTeX from sheet 'Taul1'
\begin{table}[htbp]
  \centering
  \caption{Add caption}
    \begin{tabular}{rr}
    \toprule
    Research method & Amount \\
    \midrule
    Multicase & 2 \\
    Experience report & 7 \\
    Singlecase & 19 \\
    Survey & 1 \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

% Table generated by Excel2LaTeX from sheet 'Taul1'
\begin{table}[htbp]
  \centering
  \caption{Add caption}
    \begin{tabular}{rr}
    \toprule
    Agile method & Amount \\
    \midrule
    Scrum & 15 \\
    XP    & 7 \\
    Lean  & 5 \\
    Other & 5 \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

% Table generated by Excel2LaTeX from sheet 'Taul1'
\begin{table}[htbp]
  \centering
  \caption{Add caption}
    \begin{tabular}{rr}
    \toprule
    Domain & Amount \\
    \midrule
    Telecom & 9 \\
    Enterprise information system & 10 \\
    Web application & 4 \\
    Other & 7 \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

\begin{table}
%\centering
\caption{Metrics by pdoc}
\label{Metrics} 
\begin{tabular}{lp{7cm}} \hline
ID & Metrics\\
\hline 
\cite{Cheng200929} & Team available hours, team
effective hours, critical defects sent by customer, open defects, test
failure rate\\
\cite{LNBIP01490121} & Technical debt in categories, build status,
technical debt in effort\\
\cite{Dubinsky200512} & Burndown, check-ins per day, number of automated test steps, faults
per iteration\\
\cite{Elssamadisy2002617} & Velocity\\
\cite{Green2011} & Burndown, story points, \# of open defects, defects found
in system test, defects deferred, net promoter score\\
\cite{Greening2010} & Story points, task effort, velocity\\
\cite{Haugen200623} & Effort estimate, actual effort\\
\cite{Hodgetts2004106} & \# of defects/velocity\\
\cite{Hodgkins2007194} & Revenue per customer\\
\cite{Hong2010310} & Task expected start and end date, effort estimate,
completed web pages, task done\\
\cite{Jakobsen2011168} & Fix time of failed build, story flow percentage,
percentage of stories prepared for sprint, time to establish project foundation, velocity of elaborating features,
velocity of implementing features\\
\cite{Janus20129} & Broken build, test coverage, test growth ratio, violations
of static code checks, \# of unit tests\\
\cite{Mahnic201273} & Sprint velocity, release velocity, cost performance
index, schedule performance index, planned velocity\\
\cite{Middleton2007387} & Common tempo time, number of bounce backs, cycle
time, work in progress\\
\cite{Mujtaba2010139} & Lead time, processing time, queue time\\
\cite{Petersen2010654} & Change request per requirement, fault slips,
implemented vs wasted requirements, maintenance effort\\
\cite{Petersen2011975} & Rate of requirements per phase, variance in handovers,
requirement's cost types\\
\cite{Petersen2012108} & Cumulative flow of maintenance requests, lead time\\
\cite{Petersen20101275} & \# of faults, fault-slip-through, \# of requests
from customer, \# of requirements per phase\\
\cite{Polk2011263} & Work in progress, average velocity, cycle time\\
\cite{Seikola2011321} & Lead time, work in progress, \# of days in maintenance,
\# of days to overdue, reported hours on CSR\\
\cite{Shen200725} & Adaptability, innovation, productivity,
ROI\\
\cite{Staron20113} & Throughput\\
\cite{Staron20101069} & Defect trend indicator, \# of defects, predicted \# of
defects\\
\cite{Talby200940} & Burndown, check-ins per day, number of automated test steps\\
\cite{Talby2006100} & Burndown, \# of new defects, number of written and passed tests,
task estimated vs actual time, time reported for overhead activities,
check-ins per day\\
\cite{Trapa2006243} & Story estimate, story complete percentage\\
\cite{Trimble20134826} & Progress as working code\\
\cite{Tudor2006367} & Costs, schedule\\
\hline
\end{tabular}
\end{table}

\begin{comment}
\begin{table*}
%\centering
\caption{Overview of primary studies}
\label{OverviewOfPdocs} 
\begin{tabular}{lllllp{3cm}p{8cm}} \hline
ID & Year & Resear. meth. & Agile method & Team size & Domain & Metrics\\
\hline 
\cite{Cheng200929} & 2009 & Multicase &  NA/Scrum/Scrum & 2-10/2-7/4-8
& ERP/Graphic design plug-in/Facility management & Team available hours, team
effective hours, critical defects sent by customer, open defects, test
failure rate\\
\cite{LNBIP01490121} & 2013 & Experience r. & Scrum & 25 teams & Software
for oil and gas industry & Technical debt in categories, build status,
technical debt in effort\\
\cite{Dubinsky200512} & 2005 & Singlecase & XP & 15 & Enterprise information
system & Burndown, check-ins per day, number of automated test steps, faults
per iteration\\
\cite{Elssamadisy2002617} & 2002 & Experience r. & XP & 50 & Enterprise
resource solution for the leasing industry & Velocity\\
\cite{Green2011} & 2011 & Survey & Scrum & 26 teams & Desktop and SaaS
products & Burndown, story points, \# of open defects, defects found in
system test, defects deferred, net promoter score\\
\cite{Greening2010} & 2010 & Experience r. & Scrum & 5-9 & NA & Story
points, task effort, velocity\\
\cite{Haugen200623} & 2006 & Singlecase & XPMix & 15-20 & Broadband order
system & Effort estimate, actual effort\\
\cite{Hodgetts2004106} & 2004 & Multicase & XP/Scrum & 4-18/6-9 &
b-2-b e-commerce solutions/Criminal justice system development & \# of
defects/velocity\\
\cite{Hodgkins2007194} & 2007 & Singlecase & ScrumMix & 500 & Security
services & Revenue per customer\\
\cite{Hong2010310} & 2010 & Singlecase & ScrumMix & NA & E-commerce & Task
expected start and end date, effort estimate, completed web pages, task done\\
\cite{Jakobsen2011168} & 2011 & Singlecase &
LeanScrumFDD & 5$\pm$2 & Information and communication software development & Fix time of failed
build, story flow percentage, percentage of stories prepared for sprint,
time to establish project foundation, velocity of elaborating features,
velocity of implementing features\\
\cite{Janus20129} & 2012 & Experience r. & XPMix & NA & Web application
development & Broken build, test coverage, test growth ratio, violations of
static code checks, \# of unit tests\\
\cite{Mahnic201273} & 2012 & Singlecase & Scrum & 6-8 &Web page development
& Sprint velocity, release velocity, cost performance index, schedule
performance index, planned velocity\\
\cite{Middleton2007387} & 2007 & Singlecase & Lean & Comp. 160 devs& Various
& Common tempo time, number of bounce backs, cycle time, work in progress\\
\cite{Mujtaba2010139} & 2010 & Singlecase & ScrumXPMix & Dev site 600 &
Telecom & Lead time, processing time, queue time\\
\cite{Petersen2010654} & 2010 & Singlecase & AgileMix & 6-7 & Telecom &
Change request per requirement, fault slips, implemented vs wasted
requirements, maintenance effort\\
\cite{Petersen2011975} & 2011 & Singlecase & ScrumXPMix & Dev site 500 &
Telecom & Rate of requirements per phase, variance in handovers,
requirement's cost types\\
\cite{Petersen2012108} & 2012 & Singlecase & LeanMix & NA & Telecom &
Cumulative flow of maintenance requests, lead time\\
\cite{Petersen20101275} & 2010 &  Singlecase & LeanMix & NA & Telecom &
\# of faults, fault-slip-through, \# of requests from customer,
\# of requirements per phase\\
\cite{Polk2011263} & 2011 & Experience r. & AgileMix & 9 and 6 & 
Casino games & Work in progress, average velocity, cycle time\\
\cite{Seikola2011321} & 2011 & Singlecase & ScrumBan & 6-8 & Telecom
maintenance & Lead time, work in progress, \# of days in maintenance,
\# of days to overdue, reported hours on CSR\\
\cite{Shen200725} & 2007 & Singlecase & ScrumXPMix & 4 &
Independent software developer & Adaptability, innovation, productivity,
ROI\\
\cite{Staron20113} & 2011 & Singlecase & LeanMix & project size 200 & Telecom
& Throughput\\
\cite{Staron20101069} & 2010 & Singlecase & LeanMix & project size 100 &
Telecom & Defect trend indicator, \# of defects, predicted \# of
defects\\
\cite{Talby200940} & 2009 & Singlecase & XP & 15 & Enterprise information
system & Burndown, check-ins per day, number of automated test steps\\
\cite{Talby2006100} & 2006 & Singlecase & XPMix & 15 & Enterprise information
system & Burndown, \# of new defects, number of written and passed tests,
task estimated vs actual time, time reported for overhead activities,
check-ins per day\\
\cite{Trapa2006243} & 2006 &  Experience r. & ScrumXPMix & NA & Telecom
& Story estimate, story complete percentage\\
\cite{Trimble20134826} & 2013 & Singlecase & ScrumMix & 5 & Space mission
control software & Progress as working code\\
\cite{Tudor2006367} & 2006 & Experience r. & DSDM & NA & Library software &
Costs, schedule\\
\hline
\end{tabular}
\end{table*}
\end{comment}

Categories for reasons and use of measurements are listed in
\cref{WhyHowCategories}. The following chapters will describe each category in
more detail.

\begin{table}
\centering 
\caption{Categories for why and how measurement usage}
\label{WhyHowCategories}
\begin{tabular}{c p{2,5cm}} \hline
Categories & Sources\\ \hline
\nameref{sec:IterationPlanning}&
\cite{Elssamadisy2002617,Polk2011263,Cheng200929,Greening2010,Hong2010310}
\cite{Mahnic201273,Haugen200623,Hodgkins2007194,Hodgkins2007194}\\
\nameref{sec:IterationTracking} &
\cite{Petersen2011975,Talby2006100,Mahnic201273,Dubinsky200512,Hong2010310}
\cite{LNBIP01490121,Green2011,Elssamadisy2002617,Middleton2007387,Trapa2006243}
\cite{Trimble20134826,Hodgetts2004106,Staron20101069,Seikola2011321,Polk2011263}
\cite{Greening2010,Petersen20101275}\\
\nameref{sec:Motivate} &
\cite{Trapa2006243,Talby200940,Jakobsen2011168,LNBIP01490121,Cheng200929}
\cite{Polk2011263,Staron20101069,Talby2006100}\\
\nameref{sec:ProblemIdentification} &
\cite{Petersen2011975,Trapa2006243,Middleton2007387,Jakobsen2011168,Staron20101069}
\cite{Mahnic201273,Petersen2010654,Shen200725,Mujtaba2010139,Tudor2006367,Petersen2012108}\\
\nameref{sec:PreQuality} &
\cite{Janus20129,Janus20129,Dubinsky200512,Trapa2006243}\\
\nameref{sec:PostQuality} &
\cite{Petersen2010654,Cheng200929,Green2011,Staron20101069}\\
\nameref{sec:ChangesInProcesses} &
\cite{Jakobsen2011168,Petersen2011975,Mujtaba2010139,LNBIP01490121,Staron20101069,Janus20129,Staron20113,Petersen20101275}\\
\hline
\end{tabular}
\end{table}


\subsection{Iteration planning}
\label{sec:IterationPlanning}
Many metrics were used to support iteration planning. The metrics were used for task prioritization, estimating the iteration size and team velocity. 

Many metrics were focused to help in the prioritization of the tasks for the next
iteration \cite{Greening2010,Haugen200623,Hodgkins2007194}.
Prioritization of features was affected by a metric that measured the amount of revenue a customer is willing to pay for a feature \cite{Hodgkins2007194}.

Effort estimation metrics were used to measure the size of the features
\cite{Elssamadisy2002617}.
Furthermore, velocity metrics were used to calculate how many features is the
team able to complete in an iteration \cite{Polk2011263}. Knowing the teams'
effective available hours was found useful when selecting tasks for an
iteration \cite{Cheng200929}.
Velocity metrics were also used to improve the next iteration estimates
\cite{Mahnic201273}.
\juha{Tämä task-riippuvuuden mallintaminen alku ja loppupäivineen on hyvin
epäagiilia, tästä jotain discussioniin}\eetu{Ehkä ajattelit tyyliin jotain
Gant charttihässäkkää, mutta mä en jotenkin näe tätä mitenkään epäagiilina -
enemmänkin maalaisjärjen käyttönä. Täytyyhän joku keino olla hahmottaa sitä,
jos taskeilla on riippuvuuksia. Vai oliko agiilissa tähän joku ajatusmalli
mitä en nyt saa päähäni?} In one case, task's start and end date metric was
used to point out interdependent tasks in the planning phase \cite{Hong2010310}.


\subsection{Iteration tracking} %completion}
\label{sec:IterationTracking}
% Timely manner of completing iteration is one of the cornerstones of agile
% development !ISKEVIITE.
Purpose of iteration tracking was to track how the tasks selected for the
iteration were performed and that necessary modifications were done to the
plan to complete the iteration according to schedule.
Metrics helped in monitoring, identifying problems, and predicting the end
result by making it transparent to the stakeholders how the iteration is
progressing.
\cite{Petersen2011975,Talby2006100,Mahnic201273,Dubinsky200512,Hong2010310,Green2011,Trapa2006243,Trimble20134826}.
Progress metrics included number of completed web pages \cite{Hong2010310},
story completion percentage \cite{Trapa2006243} and velocity metrics
\cite{Dubinsky200512}.
\juha{velocity metriikan käyttäminen etenemisenseurantaan on
epäagiilia->ongelmia - tästä asiaa discussioniin} \eetu{lisätty}However, using
velocity metrics had also negative effects such as cutting corners in
implementing features to maintain velocity with the cost of quality
\cite{Elssamadisy2002617}. One qualitative progress metric was product
demonstrations with customer \cite{Trimble20134826}. Measuring the completion
of tasks enabled selecting incomplete tasks to the next iteration
\cite{Hong2010310}.

%Risk management was also mentioned often, for example a metric was added
%where it seemed valuable in decreasing a risk \cite{Dubinsky200512},  
%\cite{Talby2006100}\cite{Trapa2006243}\cite{Dubinsky200512}\cite{Talby200940}.

When the metrics indicated, during an iteration, that all planned tasks could not be completed, the iteration was rescoped by cutting tasks
\cite{Mahnic201273,Dubinsky200512,Middleton2007387} or extra
resources were added \cite{Dubinsky200512,Middleton2007387}.

 % Almost anyone could walk into a team's room and with a quick glance
 % understand what is the status of the iteration.
When there were problems that needed to be fixed, whether they were short or long term, the metrics helped in making decisions to fix them
\cite{Staron20101069,Dubinsky200512,Petersen2011975,LNBIP01490121}.
It was possible to base decisions on data, not only use common sense and
experience \cite{Talby200940}. Balance of work flow was mentioned as a reason
for using metrics in multiple papers
\cite{Polk2011263,Petersen2010654,Petersen20101275,Greening2010,Petersen2011975,Dubinsky200512,Jakobsen2011168}.
%Crosstraining people to work on multiple disciplines was used to balance the
%work flow\cite{Middleton2007387}\cite{Talby200940}.  - Tämä jäi aika irralliseksi
Progress metrics were used to focus work on tasks that matter the most \cite{Talby200940}, avoid partially done work \cite{Seikola2011321}, avoid task switching \cite{Seikola2011321}
and polishing of features \cite{Talby200940}. 
\juha{epäagiili käytäntö, kerro lisää}\eetu{En näe mitään epäagiilia
tässä.}Finally, open defects metric was used
to delay a release \cite{Hodgetts2004106}.

%\subsubsection{Project progress}
%While iteration completion is important - so is the whole project's completion.
%Metrics were also used to monitor the whole project: assess risks, follow work
%completion and 

\subsection{Motivating and improving}
\label{sec:Motivate}
% (Agile methods emphasize self-empowerment - this was also visible in the
% used metrics.)
This section describes metrics that were used to motivate people and support team level
improvement of working practices and performance.

Metrics were used to communicate different data about the project or product
to the team members
\cite{Trapa2006243,Talby200940,Polk2011263,Staron20101069,Talby2006100}.
Measurement data motivated teams to act and improve their
performance\cite{Talby200940,Polk2011263,Cheng200929,LNBIP01490121,Jakobsen2011168}.
Some examples included fixing the build faster by visualizing build status
\cite{Jakobsen2011168,LNBIP01490121}, fixing bugs faster by showing amount of defects in monitors \cite{Cheng200929} and increasing testing by measuring product size by automated tests that motivated team to write more tests \cite{Talby200940}.

Metrics were also used to prevent harmful behaviour such as cherry picking
features that are most interesting to the team. \juha{WIP limit kaipaa
paremman selityksen, eihän WIP limit estä poimasta sitä mieluisinta tehtävää,
vaikka tarkeämpiäkin olisi listalla...} \eetu{Mä ymmärrän tän niin, että
tiimi ei voi nappailla muita tehtäviä ennen kuin tämänhetkinen on valmis. Ei
tuota ole tosin hirveen selkeästi kuvattu alkuperäisessä tekstissäkään:
``Teams could only work on a maximum of two features or feature level integration  at  any  one  time.  This  also stopped  teams 'cherry picking' features they wanted to develop at expense of the whole product.''}
Measuring work in progress (WIP) and setting WIP limits prevented cherry picking by enforcing only two features at a time. \cite{Middleton2007387}

\subsection{Identifying process problems}
\label{sec:ProblemIdentification}
Metrics were often used to identify or avoid problems in processes and work
flows. This chapter describes how metrics were used to spot problems.

There were multiple cases highlighting how metrics are used to identify or
predict problems in order to solve or avoid them
\cite{Petersen2011975,Trapa2006243,Mahnic201273,Petersen2010654,Shen200725,Mujtaba2010139,Tudor2006367}.

Sometimes there were work phases where no value was added, for example,
``waiting for finalization''. This type of activity was called waste and was
identified by using lead time. \cite{Petersen2012108}

\juha{Tämä mittari ei ole selkeä, täytyy avata hieman enemmän mikä se on}
\eetu{Avattu nyt hieman lisää.} Story implementation flow metric describes how
efficiently a developer has been able to complete a story compared to the estimate. This metric helped to
identify a problem with receiving customer requirement clarifications \cite{Jakobsen2011168}.

Creating awareness with defect trend indicator helped to take actions to avoid
problems \cite{Staron20101069}. One common solution to problems was to find
the root cause \cite{Jakobsen2011168,Middleton2007387}.

\subsection{Pre-release quality}
\label{sec:PreQuality}
Metrics in the pre-release quality category were used to prevent defects
reaching customers and to understand what was the current quality of the
product.

Integration fails was a problem to avoid with static code check metrics
\cite{Janus20129}. Moreover, metrics were used to make sure that the product
is sufficiently tested before the next step in the release path
\cite{Janus20129}\cite{Dubinsky200512}. Additionally, making sure that the
product is ready for further development was mentioned \cite{Green2011}.

%\juha{Tämä ei oikeastaan sano mitään, oliko tuossa joku selkeämpi ajatus,
%jotain muuta kuin nuo mainitut staattiset mittarit ja testikattavuus?}Also,
%using metrics to improve pre-release quality was a goal in one case
%\cite{Janus20129}.

Some metrics forced writing tests before the actual code \cite{Trapa2006243}.
Technical debt was measured with a technical debt board that was used to
facilitate discussion on technical debt issues \cite{LNBIP01490121}.

\subsection{Post-release quality}
\label{sec:PostQuality}
Metrics in post-release quality deal with evaluating the quality of the
product after it has been released.

Customer satisfaction, customer responsiveness, and quality indicators were
seen as attributes of post-release quality. Some metrics included customer
input to determine post-release quality
\cite{Petersen2010654,Green2011,Cheng200929} while other metrics
used pre-release data as predictors of post-release quality
\cite{Staron20101069,Petersen2010654,Green2011}. Customer related
metrics included, for example, defects sent by customers\cite{Cheng200929},
change requests from customers \cite{Petersen2010654} and customer's
willingness to recommend product to other potential customers
\cite{Green2011}.
Quality prediction metrics included defect counts \cite{Petersen2010654},
maintenance effort \cite{Staron20101069}, and deferred defect counts
\cite{Green2011}.

\subsection{Changes in processes or tools}
\label{sec:ChangesInProcesses}
This chapter describes the reported changes that applying metrics had for processes and tools. The changes include changes in measurement practices, development policies, and the whole development process.

The successful usage of sprint readiness metric and story flow metric changed
company policy to have target values for both metrics as well as monthly
reporting of both metrics by all projects \cite{Jakobsen2011168}.

At Ericsson by monitoring the flow of requirements metric they decided to
change their implementation flow from push to pull to help them deliver in a
more continuous manner. Also, based on the metric they added intermediate
release version to have release quality earlier in the development cycle.\cite{Petersen20101275}

\juha{ehkä hieman enemmän voisi paljastaa} \eetu{avattu}Changes to
requirements management were also made based on lead time in other case at
Ericsson. Analysing lead time contributed to delaying technical design after
purchase order was received, providing customer a rough estimate quickly and
merging the step to create solution proposal and technical design.
\cite{Mujtaba2010139}

Problem with broken build, and the long times to fix the build, led to
measurements that monitor and visualize the state of the build and the time it
takes to fix it \cite{LNBIP01490121,Jakobsen2011168,Janus20129}.

Also, additional code style rules were added to code check-in and build tools
so that builds would fail more often and defects would get caught before
release \cite{Jakobsen2011168,Janus20129}. 

\juha{ei avaudu}\eetu{avattu}Similarly, testing approaches were changed based
on flow metrics. Using lead time led to that integration testing could be
started paraller to system testing \cite{Mujtaba2010139}. Also, throughput of
a test process showed insufficient to handle the incoming features which led
to changing the test approach \cite{Staron20113}.

\section{Discussion}
\label{sec:Discussion}

\subsection{Implications for practice}
To provide implications to practice we map our findings to the principles of
agile software development \cite{beck2001agile} categorized by Patel \& al.
\cite{1579312}.

\mika{TODO: Pitaa selvasti tuoda esiin  mappaus. Principlet jarjestykseen.
Viite mista principlet tulee. Joka principlen kohdalta ensin mika sita tukee.
 Ja sitten jos loydettiin jotain ristiriittaista periaatteen kanssa. 
 Lisaksi principlet jarjestykseen.  Ja lopuksi mille principlelle ei ollut
 mittareita.  
  -> Future work Pitaisiko olla ja millaisia} \eetu{Done. paitsi Future work.} 

Communication and Collaboration (4,6) was reflected in metrics that motivated
team to act and improve, see \cref{sec:Motivate}. Also, progress metrics were
used to communicate the status of the project to the stakeholders, see
\cref{sec:IterationTracking}.

Team involvement (5,8) was reflected in metrics that motivated team to act and
improve, see \cref{sec:Motivate}. Also, to promote sustainable development
metrics were targeted to balance the flow of work, see
\cref{sec:IterationTracking}.

Reflection (12) was visible in metrics that were used to identify problems and
to change processes, see \cref{sec:ProblemIdentification} and
\cref{sec:ChangesInProcesses}.

Frequent delivery of working software (1,3,7) was directly identified in one
paper, where the team measured progress by demonstrating the product to the
customer \cite{Trimble20134826}. Additionally, there were cases where for
example completed web-pages \cite{Hong2010310} were the primary progress
measure. Also, many metrics focused on progress tracking and timely completion
of the iteration, see \cref{sec:IterationTracking}. However, some other
measures from \cref{sec:IterationTracking} show that instead of working code
agile teams followed completed tasks and velocity metrics.

Managing Changing Requirements (2) was seen in the metrics that support
prioritization of features each iteration, see \cref{sec:IterationPlanning}.
Additionally, different metrics helped keeping the internal quality of the
product high throughout the development which then provided safe development
of modifications from new ideas, see \cref{sec:PreQuality}.

Design (9,10,11) was seen in focus to measuring technical debt and using
metrics to enforce writing tests before actual code, see
\cref{sec:PreQuality}. Additionally, the status of build was continuously
monitored, see \cref{sec:ChangesInProcesses}. However, the use of velocity
metric had a negative effect on technical quality, see
\cref{sec:IterationTracking}.
% was seen from different perspectives: on one hand metrics focused on
% problem/waste identification, see \cref{sec:ProblemIdentification},
Many metrics focused on making sure that the right features were selected for
implementation, see \cref{sec:IterationPlanning}, thus avoiding unnecessary
work.

\begin{comment}

Agile principle \#1: ``Our highest priority is to satisfy the customer through
early and continuous delivery of valuable software.'' was seen in the team
measuring progress by demonstrating the product to the customer
\cite{Trimble20134826}.

Agile principle \#2: ``Welcome changing requirements, even late in
development. Agile processes harness change for the customer's competitive
advantage.'' was seen in the metrics that support prioritization of features
per iteration, see \cref{sec:IterationPlanning}. Additionally, different
metrics helped keeping the internal quality of the product high throughout the
development which then provided safe development of modifications and new
ideas, see \cref{sec:PreQuality}.

Agile principle \#3: ``Deliver working software frequently, from a couple of
weeks to a couple of months, with a preference to the shorter timescale''  was
seen in many metrics focusing on tracking and timely completion of the
iteration, see \cref{sec:IterationTracking}

Agile principle \#4:``Business people and developers must work 
together daily throughout the project.'' was seen how different metrics
were used to share information to all stakeholders about the project, see
\cref{sec:Motivate} and \cref{sec:IterationTracking}. 

Agile principle \#5:``Build projects around motivated individuals. Give them
the environment and support they need, and trust them to get the job done''
was reflected in metrics that motivated team to act and improve, see
\cref{sec:Motivate}.

Agile principle \#6:``The most efficient and effective method of 
conveying information to and within a development 
team is face-to-face conversation.'' was seen in \cite{LNBIP01490121} where
a technical debt board measuring the level of technical debt was used to
facilitate face-to-face discussion on technical debt issues, see
\ref{sec:PreQuality}. 

Agile principle \#7:``Working software is the primary measure of progress'' 
was directly identified in one paper, where the team measured progress by
demonstrating the product to the customer. Additionally, there were cases
where for example completed web-pages \cite{Hong2010310} were the primary
progress measure. However, some other measures from \cref{sec:IterationTracking} show that instead of working code agile teams followed completed tasks and velocity metrics.

Agile principle \#8:``Agile processes promote sustainable development. The
sponsors, developers, and users should be able to maintain a
constant pace indefinitely.'' was followed with metrics targeted to balance
the flow of work, see \cref{sec:IterationTracking}.

Agile principle \#9:``Continuous attention to technical excellence 
and good design enhances agility.'' was seen in focus to measuring technical
debt and using metrics to enforce writing tests before actual code, see
\cref{sec:PreQuality}. Additionally, the status of build was continuously
monitored, see \cref{sec:ChangesInProcesses}. However, the use of velocity
metric had a negative effect on technical quality, see
\cref{sec:IterationTracking}.

Agile principle \#10:``Simplicity---the art of maximizing the amount 
of work not done---is essential.'' was seen from different perspectives: on one
hand metrics focused on problem/waste identification, see
\cref{sec:ProblemIdentification}, and on the other hand many metrics focused
on making sure that the right features were selected for implementation, see
\cref{sec:IterationPlanning}.

Agile principle \#11:``The best architectures, requirements, and designs
emerge from self-organizing teams.'' was seen in metrics that motivate the
team to improve, see \cref{sec:Motivate}. Other perspective is that since
effort estimation is done by the team, the team is then more motivated to
accomplish the goal, see \cref{sec:IterationPlanning}.

Agile principle \#12: ``At regular intervals, the team reflects on how to
become more effective, then tunes and adjusts its behavior accordingly'' was
visible in metrics that were used to identify problems and to change
processes, see \cref{sec:ProblemIdentification} and 
\cref{sec:ChangesInProcesses}.

\end{comment}

\eetu{Mun mielestä seuraavat mittarit ei oo niin ketteriä, mut en osaa oikeen
perustella miksi tai sanoa mitä periaatteita vastaan ne olisi: maintenance
effort, cost types, defect amounts(?), defects deferred, revenue per
customer(?), time to establish project foundation, test coverage, test growth
ratio, cost performance index, schedule performance index. Näitä ei kaikkia
ole myöskään kuvattu resultseissa, paitsi taulukossa mainittu.}

There were also metrics or their usage which were not agile in nature. E.g
maintaining velocity by cutting corners in quality instead of dropping
features from that iteration \cite{Elssamadisy2002617}. Also, adding people to
project to reach a certain date \cite{Dubinsky200512, Middleton2007387} doesn't seem that
agile compared to removing tasks. Adding people can have a negative impact to
progress, considering the lack of knowledge and training time required.

While the flow metrics Ericsson have a good target of balancing workflow, they
seem  (or at least they are presented) complicated to use - meaning that one
might need considerable effort generate and analyse the metrics, which
doesn't fit to the light-weightness of agile. 

Contradictory to \#5, Talby et al [viite] enforce writing automated test
cases as a measure of progress - so in a way they didn't trust the developers to write
the test on their own? Similarly, [viite] measured the status of the build to
make developers fix the build faster - again, not trusting them to do it on
their own.


\subsection{Implications for research}
It was interesting to notice that there wasn't many code metrics, only the
ones mentioned in \cite{Janus20129} even though we feel there are many studies
regarding the benefits of code metrics. Maybe there are some practical
problems implementing and analysing the data from code metrics?

How to measure unmeasured agile principles...

In general, we think there were many metrics that were targeted for the team -
instead of high focus on managerial or upper management reporting metrics.
Making metrics visible for the team enables them to independently act and
improve without the need of rapid supervision and telling people what to do.


\eetu{(toinen judu mitä täällä voisi olla niin vertailu perinteisiin tai
agiilikirjallisuudessa suositeltuihin)
(kolmas judu: Koodimittarit oli aika heikosti edustettuna - vain muutama.
Joka on sin?ns? mielenkiintoista koska tutkimuksissa ne on hyvin
edustettuna(kai). Mut ilmeisesti tila tulee vastaan ni nää vois unohtaa
toistaiseksi}


\subsection{Limitations}
Telecommunications sector is widely represented in this study with eight
papers from Ericsson. Also, Israeli Air Force was presented in three
papers.

Sometimes it was hard to understand which metrics an author was referring
when a ``why'' was described. Moreover, we had to sometimes assume that when
author describes the reasons for using a tool, he would be actually talking
about the metrics the tool shows.

Whenever a new coding rule was decided it was hard to make sure that all
previously coded primary documents would get the same treatment.

Coding ``sense'' improved over time so it is possible that some
information was not spotted from the primary documents in the beginning of the
study.

It is possible that researcher bias could have had an effect on the results.
First author has positive mindset towards agile methods, as well as towards
certain metrics over others.


\section{Conclusions}
\label{sec:Conclusions}

This paper presents the preliminary results from a systematic literature
review from 29 primary studies. Results indicate that the reasons and use of
metrics is focused on the following areas:
\nameref{sec:IterationPlanning}, \nameref{sec:IterationTracking},
\nameref{sec:Motivate}, \nameref{sec:ProblemIdentification},
\nameref{sec:PreQuality},
\nameref{sec:PostQuality} and \nameref{sec:ChangesInProcesses}.

Researchers and practitioners can use this study to find relevant sources
regarding their interests and contexts.

\subsection{Comparison to other studies}
Hartmann \& Dymond \cite{1667571} also highlight process improvement as one of
the reasons for measurement in their agile metrics paper. Also, they emphasize
that creation of value should be the primary measure of progress - which was
also seen in our study. 

Korhonen \cite{Korhonen2009} found in her study that traditional defect
metrics could be reused in agile context - if modified. Defect metrics were also used in many of the
primary studies.

It is interesting to note how many code metrics are identified in Kitchenham's
mapping study \cite{kitchenham_whats_2010} compared to the lack of code
metrics in our study. The reasons for the lack of code metric usage in agile contexts should be studied to
evaluate the necessity of code metric research - or how code metric research
could be modified to support agile development better. The lone case in
our study where code metrics were used, the code metric usage was abstracted
to a build tool, which would just indicate an error or broken build \cite{Janus20129}. Maybe
the use of code metrics should be heavily implemented through automated tools
that handle the collection and analysing of code metric data?


We also map the found metrics to the principles of Agile Manifesto
\cite{beck2001agile}.

\eetu{So what now? What did we learn and what should be done now? Mitä nämä
tulokset merkitsee?Ainakin voisin sanoa että ihan mukavasti löyty materiaalia.
Jonkin verran löytyi samanlaisia asioita eri papereista. Tietyllä tapaa
kiinnostaisi vertailu perinteisiä mittareita vastaan. Onko näillä mittareilla
loppupeleissä mitään eroa jo vuosikausia käytössä ollleihin mittareihin
nähden? Onko jotain yhdistäviä konteksteja havaittavissa jolloin voisi
yleistää havaintoja? Myös lista tärkeiksi koetuista mittareista olisi kiva
(tämähän mulla on jo pienellä alulla). Voinko suositella tuloksissa esiteltyjä
mittareita?}

\eetu{Toinen yritys pohdiskeluun. Mitä voisi sanoa tuloksissa mainitusta
jaottelusta - mitä se jaottelu yrittää sanoa? Mittareita käytetään tietyissä
ohjelmistokehityksen vaiheissa, sekä tietynlaisissa tilanteissa, esim.
motivoimiseen tai paremminkin tiimin itsenäisen toiminnan tukena. Vaiheet
ovat siis, suunnittelu, implementaatio(sisältäen testauksen). Lisäksi laatuun
kiinnitettiin huomiota ennen ja jälkeen releassin. Viimeisenä mittareiden
tarkoituksena oli prosessiongelmien löytäminen ja ratkaiseminen prosesseja ja
työkaluja muuttamalla. Eli jos haluat muutoksia prosessiin, kannattaa ehkä
tunnistaa ongelmat mittaamalla. Mittaamalla saat mututuntuman lisäksi muutakin
todistusaineistoa ongelman tunnistamiseen. }

\eetu{Timon inspiroimana: Pitäis verrata aikaisempaa kirjallisuutta
näihän tuloksiin: Dymond puolestaan listaa agiilien mittarien heuristiikkoja,
voisi tutkia miten löydetyt mittarit noudattavat heuristiikkoja. Ja vielä tämä, että näin laajaa tutkimusta ei ole ennen tehty
(tämä pitäisi olla jo itsessään mielekäs concludaus?). Jos nyt kuitenkin
kattoo tuloksia - voisi ehkä sanoa että ei löytynyt mitenkään yhtä settiä
mittareita - vaan eri mittareita oli melkein yhtä paljon kuin papereita.
Toisaalta esim. effort estimate oli edustettuna monessa. Jostain paperista
vois kaivaa ``miksi mitataan'' ja vertailla näitä tuloksia niihin - löytyykö
samat yllä mainitut syy-alueet. Tukevatko tämän hetken agiilityökalut em.
mittareiden käyttöä(aivan liian laaja, mut ilmeisesti tällaiset heitot vois
olla further research topicseja?)}

%\end{document}  % This is where a 'short' article might terminate
%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
U-QASAR rahoitus?

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\appendix
%Appendix A
\section{Search strings}
\label{app:Strings}

The first search string was:

TITLE-ABS-KEY(software AND (agile OR lean OR "crystal method" OR "crystal
clear" OR dsdm OR "dynamic systems development method" OR fdd OR "feature
driven development" OR "agile unified process" OR "agile modeling" OR scrumban
OR kanban OR scrum OR "extreme programming" OR xp) AND (measur* OR metric OR
diagnostic OR monitor*)) AND (LIMIT-TO(SUBJAREA, "COMP")) AND
(LIMIT-TO(LANGUAGE, "English"))

It found 512 hits 19 September 2013.

%Then we noticed that some previously found key papers were missing from the
%hits because they were under sub area ``Engineering'', thus 
The second search string was:

TITLE-ABS-KEY(software AND (agile OR lean OR "crystal method" OR "crystal
clear" OR dsdm OR "dynamic systems development method" OR fdd OR "feature
driven development" OR "agile unified process" OR "agile modeling" OR scrumban
OR kanban OR scrum OR "extreme programming" OR xp) AND (measur* OR metric OR
diagnosticOR monitor*)) AND (LIMIT-TO(LANGUAGE, "English")) AND
(LIMIT-TO(SUBJAREA, "ENGI")) AND (EXCLUDE (SUBJAREA, "COMP") OR
EXCLUDE(SUBJAREA, "PHYS") OR EXCLUDE(SUBJAREA,"MATE") OR EXCLUDE (SUBJAREA,
"BUSI") OR EXCLUDE(SUBJAREA, "MATH") OR EXCLUDE(SUBJAREA, "ENVI") OR
EXCLUDE (SUBJAREA, "EART") OR EXCLUDE(SUBJAREA, "DECI") OREXCLUDE (SUBJAREA,
"ENER"))

It found 220 hits 7 November 2013.

The third search string was:

TITLE-ABS-KEY(software AND (agile OR lean OR "crystal method" OR "crystal
clear" OR dsdm OR "dynamic systems development method" OR fdd OR "feature
driven development" OR "agile unified process" OR "agile modeling" OR scrumban
OR kanban OR scrum OR "extreme programming" OR xp) AND (measur* OR metric OR
diagnosticOR monitor*)) AND (LIMIT-TO(LANGUAGE, "English")) AND
(LIMIT-TO(SUBJAREA, "BUSI")) AND (EXCLUDE (SUBJAREA, "ENGI") OR
EXCLUDE(SUBJAREA, "COMP"))

It found 42 hits 10 December 2013.

\section{Inclusion and exclusion criteria}
\label{app:Criteria}

Inclusion criteria
\begin{itemize}
  \item Papers that present the use and experiences of metrics in an agile
  industry setting.
\end{itemize}

Exclusion criteria\juha{Tiivistin exclusion kriteerejä}
\begin{itemize}
  \item Papers that don't contain empirical data from industry cases.
  \item Papers that are not in English.
  \item Papers that don't have agile context. There is evidence of
  clearly non-agile practices or there is no agile method named. For example,
  paper mentions agile but case company has only three releases per year.
  \item Paper is only about one agile practice, which is not related to
  measuring.
  \item Papers that don't seem to have any data about metric usage. Similarly,
  if there are only a few descriptions of metrics but no other info regarding
  reasons or usage.
  \item Papers that have serious issues with grammar or vocabulary and
  therefore it takes considerable effort to understand sentences.
  %\item Papers that refer to another paper where the actual case is discussed.
  %\item Papers that are in academic or semi-academic setting - customer or
  %part of workers are from industry. The reason for this is that it doesn't
  %fully represent industry setting as software development methods are likely
  %enforced by academia. \juha{tämä sisältyy tai vain tarkentaa ensimmäistä}
  \item Papers where the setting is not clear or results cannot be separated by setting, for example
  surveys where there is data both from academia and industry. %Similar
%  exclusion if results cannot be separated by software development method. 
  %\item Papers where the setting is not clear. For example only mention of
  %context is ``100 junior developers''.\juha{yhdistin edelliseen}

  %%\item Papers that are full conference proceedings. Individual papers should be already listed separately.
  \item Papers where the measurements are only used for the research. For
  example author measures which agile practices correlate with success.
  %%\item Papers that don't even show measurement usage in a pilot setting. For
  %%example method or metric is used against static industrial data set. \juha{tämä sisältyy tai vain tarkentaa ensimmäistä}
\end{itemize}

% This next section command marks the start of
% Appendix B, and does not continue the present hierarchy
%\balancecolumns % GM June 2007
% That's all folks!
\end{document}
